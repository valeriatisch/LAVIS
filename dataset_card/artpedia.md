Samples from the Artpedia dataset (Image credit: "https://aimagelab.ing.unimore.it/imagelab/page.asp?IdPage=35").

# Artpedia: A New Visual-Semantic Dataset with Visual and Contextual Sentences

## Description

(from "https://aimagelab.ing.unimore.it/imagelab/page.asp?IdPage=35")
Artpedia contains a collection of 2,930 painting images, each associated to a variable number of textual descriptions. Each sentence is labelled either as a visual sentence or as a contextual sentence, if does not describe the visual content of the artwork. Contextual sentences can describe the historical context of the artwork, its author, the artistic influence or the place where the painting is exhibited. As in standard cross-modal datasets, the association between sentences and painting is also provided. The dataset contains 9,173 labelled as visual sentences.


## Task

(from https://paperswithcode.com/task/image-captioning)

**Image captioning** is the task of describing the content of an image in words. This task lies at the intersection of computer vision and natural language processing. Most image captioning systems use an encoder-decoder framework, where an input image is encoded into an intermediate representation of the information in the image, and then decoded into a descriptive text sequence.


## Metrics
Models are typically evaluated according to a [BLEU](https://aclanthology.org/P02-1040/) or [CIDER](https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Vedantam_CIDEr_Consensus-Based_Image_2015_CVPR_paper.pdf) metric.


## References
Artpedia: A New Visual-Semantic Dataset with Visual and Contextual Sentences; Stefanini, Matteo and Cornia, Marcella and Baraldi, Lorenzo and Corsini, Massimiliano and Cucchiara, Rita; Proceedings of the International Conference on Image Analysis and Processing;2019